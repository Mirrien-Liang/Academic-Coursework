distMatrix = matrix(NA, nrow= nrow(X), ncol = nrow(cluster_centers))
for(j in 1:nrow(cluster_centers)) {
for(i in 1:nrow(X)) {
distMatrix[i,j]<-dist(rbind(X[i,],cluster_centers[j,]), method = "manhattan")
}
}
distMatrix
}
kmedian <- function(x,K,iters) {
x = as.matrix(x)
set.seed(100)
K <- x[sample(nrow(x), K),]
cluster_his <- vector(iters, mode = "list")
center_his <- vector(iters, mode = "list")
for(i in 1:iters) {
dists = cluster_dist(x,K)
clusters <- apply(dists,1,which.min)
centers <- apply(x,2,tapply,clusters,median)
cluster_his[[i]] <- clusters
center_his[[i]] <- centers
}
list(clusters = cluster_his[[1]], centers=center_his[[1]])
}
kmedian(df,3,10)
manhattan2<-function(x,K){
distance = matrix(NA, nrow= nrow(x), ncol = nrow(K))
for(j in 1:nrow(K)) {
for(i in 1:nrow(x)) {
distMatrix[i,j]<-dist(rbind(x[i,],K[j,]), method = "manhattan")
}
}
return(distance)
}
kmedian <- function(x,K,iters) {
# convert df to matrix
x = as.matrix(x)
# randomly sample some centers, set a seed 100
set.seed(100)
K <- x[sample(nrow(x), K),]
assignments <- vector(iters, mode = "list")
locations <- vector(iters, mode = "list")
for(i in 1:iters) {
dists = manhattan(x,K)
clusters <- apply(dists,1,which.min)
centers <- apply(x,2,tapply,clusters,median)
assignments[[i]] <- clusters
locations[[i]] <- centers
}
list(assignments = assignments[[1]], locations=locations[[1]])
}
kmedian(df,3,10)
sample(10,3)
sample(10,3)
df[sample(nrow(df),3)]
df[sample(nrow(df),3),]
df[sample(nrow(df),3),]
seq(1)
seq(1:10)
seq(1:3,10)
seq(1:3)
seq(1:3,by=10)
seq(1,3,by=10)
seq(from=1,to=3,by=10)
seq(from=1,to=3)
seq(from=1,to=3,length.out=10)
rep.int(1:3,2)
rep.int(1:3,5)
((100-1)%3)+1
((100-1)%%3)+1
((101-1)%%3)+1
((102-1)%%3)+1
((103-1)%%3)+1
for (i in 1:195) {
c = ((i-1)%%3)+1
}
c
for (i in 1:195) {
print(((i-1)%%3)+1)
}
kmedian2 <- function(x,K,iters) {
# convert df to matrix
x = as.matrix(x)
# randomly sample some centers, set a seed 100
set.seed(100)
K <- x[sample(nrow(x), K),]
# empty lists to store outputs
assignments <- vector(iters, mode = "list")
locations <- vector(iters, mode = "list")
# initialize cluster assignments using ((i-1)%K)+1
for (i in 1:nrow(x)) {
assignments[i] = ((i-1)%%K)+1
}
for(i in 1:iters) {
# call manhattan distance helper function
dists = manhattan(x,K)
# find minimum distance
clusters <- apply(dists,1,which.min)
# tapply median()
centers <- apply(x,2,tapply,clusters,median)
# append outputs
assignments[[i]] <- clusters
locations[[i]] <- centers
}
# return outputs in list
return(list(locations=locations[[1]], assignments = assignments[[1]]))
}
df = read.csv("parkinsons.data",row.names = 1)
kmedian(df,3,1000)
result = kmedian(df,3,1000)
print(result$locations)
euclid <- function(x,K){
distance = matrix(NA, nrow= nrow(x), ncol = nrow(K))
for(j in 1:nrow(K)) {
for(i in 1:nrow(x)) {
distMatrix[i,j]<-dist(rbind(x[i,],K[j,]), method = "euclidean")
}
}
return(distance)
}
mykmeans <- function(x,K,iters) {
# convert df to matrix
x = as.matrix(x)
# randomly sample some centers, set a seed 100
set.seed(100)
K <- x[sample(nrow(x), K),]
# empty lists to store outputs
assignments <- vector(iters, mode = "list")
locations <- vector(iters, mode = "list")
for(i in 1:iters) {
# call euclidean distance helper function
dists = euclid(x,K)
# find minimum distance
clusters <- apply(dists,1,which.min)
# tapply mean()
centers <- apply(x,2,tapply,clusters,mean)
# store outputs
assignments[[i]] <- clusters
locations[[i]] <- centers
}
# return outputs in list
return(list(locations=locations[[1]], assignments = assignments[[1]]))
}
# df = read.csv("parkinsons.data",row.names = 1)
mykmeans(df,3,10)
manhattan2<-function(x,K){
distance = matrix(NA, nrow= nrow(x), ncol = nrow(K))
for(j in 1:nrow(K)) {
for(i in 1:nrow(x)) {
distance[i,j]<-dist(rbind(x[i,],K[j,]), method = "manhattan")
}
}
return(distance)
}
euclid <- function(x,K){
distance = matrix(NA, nrow= nrow(x), ncol = nrow(K))
for(j in 1:nrow(K)) {
for(i in 1:nrow(x)) {
distance[i,j]<-dist(rbind(x[i,],K[j,]), method = "euclidean")
}
}
return(distance)
}
mykmeans <- function(x,K,iters) {
# convert df to matrix
x = as.matrix(x)
# randomly sample some centers, set a seed 100
set.seed(100)
K <- x[sample(nrow(x), K),]
# empty lists to store outputs
assignments <- vector(iters, mode = "list")
locations <- vector(iters, mode = "list")
for(i in 1:iters) {
# call euclidean distance helper function
dists = euclid(x,K)
# find minimum distance
clusters <- apply(dists,1,which.min)
# tapply mean()
centers <- apply(x,2,tapply,clusters,mean)
# store outputs
assignments[[i]] <- clusters
locations[[i]] <- centers
}
# return outputs in list
return(list(locations=locations[[1]], assignments = assignments[[1]]))
}
# df = read.csv("parkinsons.data",row.names = 1)
mykmeans(df,3,10)
kmeans(df,3)
kmeans(df,3)$cluster
kmeans(df,3,10)
kmeans(df,3,10)$cluster[1]
kmeans(df,3,10)$cluster[[1]]
# df = read.csv("parkinsons.data",row.names = 1)
result2 = mykmeans(df,3,10)
result3 = kmeans(df,3,10)$cluster[[1]]
v1 = result2$assignments
v2 = c()
for (i in seq_along(result3$cluster)) {
v2[i] = result3$cluster[[i]]
}
result3 = kmeans(df,3,10)
v1 = result2$assignments
v2 = c()
for (i in seq_along(result3$cluster)) {
v2[i] = result3$cluster[[i]]
}
v2
v1
compare1 = data.frame(mykmeans = v1, kmeans = v2)
compare1
compare1 = data.frame(mykmeans = v1, kmeans = v2, difference = abs(v1-v2))
compare1
data.frame(mykmeans = v1, kmeans = v2)
result3 = kmeans(df,3,10)
# Compare cluster assignments
v1 = result2$assignments
v2 = c()
for (i in seq_along(result3$cluster)) {
v2[i] = result3$cluster[[i]]
}
data.frame(mykmeans = v1, kmeans = v2)
?count()
sum(v1 == 1)
sum(v1 == c(1,2,3))
compare1 = data.frame(cluster = c(1,2,3),
count_mykmeans = c(sum(v1 == 1), sum(v1==2),sum(v1==3)),
count_kmeans = c(sum(v2==1),sum(v2==2),sum(v2==3))
)
compare1
set.seed(123)
# df = read.csv("parkinsons.data",row.names = 1)
result2 = mykmeans(df,3,10)
set.seed(123)
# df = read.csv("parkinsons.data",row.names = 1)
result2 = mykmeans(df,3,10)
set.seed(123)
result3 = kmeans(df,3,10)
compare1
compare2
# df = read.csv("parkinsons.data",row.names = 1)
result2 = mykmeans(df,3,10)
set.seed(123)
result3 = kmeans(df,3,10)
# Compare cluster assignments
v1 = result2$assignments
v2 = c()
for (i in seq_along(result3$cluster)) {
v2[i] = result3$cluster[[i]]
}
compare1 = data.frame(mykmeans = v1, kmeans = v2)
compare2 = data.frame(cluster = c(1,2,3),
count_mykmeans = c(sum(v1 == 1), sum(v1==2),sum(v1==3)),
count_kmeans = c(sum(v2==1),sum(v2==2),sum(v2==3))
)
compare1
compare2
result2
result3$centers
compare3 = list(mykmeans = result2$locations,
kmeans = result3$centers)
compare3
read.table("test2_data.txt")
rnorm(10,0,10)
set.seed(100)
sample_df = data.frame(rnorm(50,0,10),rnorm(50,0,10))
head(sample_df)
set.seed(100)
sample_df = data.frame(V1 = rnorm(50,0,10), V2 = rnorm(50,0,10))
head(sample_df)
mykmeans(sample_df,3,10)
set.seed(100)
result02 = kmeans(sample_df,3,10)
result02
result01 = mykmeans(sample_df,3,10)
result01
result01 = mykmeans(sample_df,3,10)
result01
set.seed(100)
result02 = kmeans(sample_df,3,10)
result02
set.seed(222)
result02 = kmeans(sample_df,3,10)
result02
result01
result01.centers <- aggregate(.~assignments,result01,mean)
result01.centers <- aggregate(result01$assignments,result01,mean)
result01.centers <- aggregate(.~locations,result01,mean)
# Sample data
set.seed(100)
xval <- rnorm(12, mean = rep(1:3, each = 4), sd = 0.2)
yval <- rnorm(12, mean = rep(c(1,2,1), each = 4), sd = 0.2)
# Kmeans function with random.seed for initialization
kclus <- function(x, y, nclus, random.seed=123) {
set.seed(random.seed)
# start with random cluster centers
xcen <- runif(n = nclus, min = min(x), max = max(x))
ycen <- runif(n = nclus, min = min(y), max = max(y))
# data points and cluster assignment in "data"
# cluster coordinates in "clus"
data <- data.frame(xval = x, yval = y, clus = NA)
clus <- data.frame(name = 1:nclus, xcen = xcen, ycen = ycen)
finish <- FALSE
while(finish == FALSE) {
# assign cluster with minimum distance to each data point
for(i in 1:length(x)) {
dist <- sqrt((x[i]-clus$xcen)^2 + (y[i]-clus$ycen)^2)
data$clus[i] <- which.min(dist)
}
xcen_old <- clus$xcen
ycen_old <- clus$ycen
# calculate new cluster centers
for(i in 1:nclus) {
clus[i,2] <- mean(subset(data$xval, data$clus == i))
clus[i,3] <- mean(subset(data$yval, data$clus == i))
}
# stop the loop if there is no change in cluster coordinates
if(identical(xcen_old, clus$xcen) & identical(ycen_old, clus$ycen)) finish <- TRUE
}
data
}
# with default random seed 123, you should be able to reproduce the result
# as you can see, in this case, no data points were assigned to the 4th cluster
cluster <- kclus(xval, yval, 4)
cluster
aggregate(.~clus, cluster, mean)
result01.centers <- results01$locations
result01.centers <- result01$locations
library(tidyverse)
result01$assignments
result01$locations
result01
library(ggpubr)
install.packages("ggpubr")
install.packages("factoextra")
library(ggpubr)
library(factoextra)
fviz_cluster(result02, data = df,
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
kmeans(scale(sample_df),3,1000)
# Use mykmeans()
result01 = mykmeans(scale(sample_df),3,1000)
result01
# Use kmeans()
set.seed(222)
result02 = kmeans(scale(sample_df),3,1000)
result02
result02$cluster
fviz_cluster(result02, data = sample_df,
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
result01$assignments
fviz_cluster(result01, data = sample_df,
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
result02
typeof(result02)
fviz_cluster(result02$cluster, data = sample_df,
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
fviz_cluster(result02, data = sample_df,
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
attribute(result02)
attributes(result02)
attributes(result01)
fviz_cluster(list(data = sample_df, cluster = result01$assignments), data = sample_df,
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
plot1 = fviz_cluster(list(data = sample_df, cluster = result01$assignments),
data = sample_df,
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
plot2 = fviz_cluster(result02, data = sample_df,
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
figure <- ggarrange(plot1, plot2, labels = c("mykmeans", "kmeans"),
ncol=2,nrow=1)
figure
# Combine two plots to visualize comparison
figure <- ggarrange(plot1, plot2,
ncol=2,nrow=1)
# Output the combined plot
figure
?ggarrange
# Combine two plots to visualize comparison
figure <- ggarrange(plot1, plot2, labels = c("mykmeans", "kmeans"),
label.x = 0, label.y = 2,
ncol=2,nrow=1)
# Output the combined plot
figure
# Combine two plots to visualize comparison
figure <- ggarrange(plot1, plot2, labels = c("mykmeans", "kmeans"),
label.x = 4, label.y = 0,
ncol=2,nrow=1)
# Output the combined plot
figure
# Combine two plots to visualize comparison
figure <- ggarrange(plot1, plot2, labels = c("mykmeans", "kmeans"),
label.x = 4, label.y = 0,
ncol=2,nrow=1)
# Output the combined plot
figure
# Combine two plots to visualize comparison
figure <- ggarrange(plot1, plot2, labels = c("mykmeans", "kmeans"),
label.x = 2, label.y = 1,
ncol=2,nrow=1)
# Output the combined plot
figure
# Combine two plots to visualize comparison
figure <- ggarrange(plot1, plot2, labels = c("mykmeans", "kmeans"),
label.x = 1, label.y = 1,
ncol=2,nrow=1)
# Output the combined plot
figure
# Combine two plots to visualize comparison
figure <- ggarrange(plot1, plot2, labels = c("mykmeans", "kmeans"),
label.x = 0.2, label.y = 1,
ncol=2,nrow=1)
# Output the combined plot
figure
manhattan <- function(p1,p2) {
distance <- matrix(NA, nrow=dim(p1)[1], ncol=dim(p2)[1])
for(i in 1:nrow(p2)) {
distance[,i] = rowSums(abs(t(t(p1)-p2[i,])))
}
return(distance)
}
kmedian2 <- function(x,K,iters) {
# convert df to matrix
x = as.matrix(x)
# randomly sample some centers, set a seed 100
set.seed(100)
K <- x[sample(nrow(x), K),]
# empty lists to store outputs
assignments <- vector(iters, mode = "list")
locations <- vector(iters, mode = "list")
# initialize cluster assignments using ((i-1)%K)+1
for (i in 1:nrow(x)) {
assignments[i] = ((i-1)%%K)+1
}
for(i in 1:iters) {
# call manhattan distance helper function
dists = manhattan(x,K)
# find minimum distance
clusters <- apply(dists,1,which.min)
# tapply median()
centers <- apply(x,2,tapply,clusters,median)
# store outputs
assignments[[i]] <- clusters
locations[[i]] <- centers
}
# return outputs in list
return(list(locations=locations[[1]], assignments = assignments[[1]]))
}
df = read.csv("parkinsons.data",row.names = 1)
result = kmedian2(df,3,1000)
warnings()
kmedian2 <- function(x,K,iters) {
# convert df to matrix
x = as.matrix(x)
# randomly sample some centers, set a seed 100
set.seed(100)
K <- x[sample(nrow(x), K),]
# empty lists to store outputs
assignments <- vector(iters, mode = "list")
locations <- vector(iters, mode = "list")
# initialize cluster assignments using ((i-1)%K)+1
for (i in 1:nrow(x)) {
assignments[[i]] = ((i-1)%%K)+1
}
for(i in 1:iters) {
# call manhattan distance helper function
dists = manhattan(x,K)
# find minimum distance
clusters <- apply(dists,1,which.min)
# tapply median()
centers <- apply(x,2,tapply,clusters,median)
# store outputs
assignments[[i]] <- clusters
locations[[i]] <- centers
}
# return outputs in list
return(list(locations=locations[[1]], assignments = assignments[[1]]))
}
df = read.csv("parkinsons.data",row.names = 1)
result = kmedian2(df,3,1000)
print(result$locations)
